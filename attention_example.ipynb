{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CBAM_Channel_Attention_Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChannelAttentionModule(nn.Module):\n",
    "    def __init__(self,in_channels,ratio):\n",
    "        super(ChannelAttentionModule,self).__init__()\n",
    "        self.maxpool = nn.AdaptiveMaxPool2d(1)\n",
    "        self.avgpool = nn.AdaptiveMaxPool2d(1)\n",
    "        \n",
    "        self.sharedMlP = nn.Sequential(\n",
    "                         nn.Conv2d(in_channels,in_channels//ratio,stride=1,bias=False),\n",
    "                         nn.ReLU(),\n",
    "                         nn.Conv2d(in_channels//ratio,in_channels,1,bias=False))\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    def forward(self,x):\n",
    "        maxpool_output = self.sharedMlP(self.maxpool(x))\n",
    "        avgpool_output = self.sharedMlP(self.avgpool(x))\n",
    "        output = self.sigmoid(maxpool_output + avgpool_output)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpatialAttentionModule(nn.Module):\n",
    "    def __init__(self,kernel_size=7):\n",
    "        super(SpatialAttentionModule,self).__init__()\n",
    "        assert kernel_size in (3,7),\"kernel size must be 3 or 7\"\n",
    "        padding = 3 if kernel_size == 7 else 1\n",
    "        \n",
    "        self.conv = nn.Conv2d(2,1,kernel_size,padding=padding,bias=False)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    def forward(self,x):\n",
    "        max_output,_ = torch.max(x,dim=1)\n",
    "        avg_output = torch.mean(x,dim=1)\n",
    "        x = torch.cat([max_output,avg_output],dim=1)\n",
    "        x = self.conv(x)\n",
    "        output = self.sigmoid(x)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SE attention "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SEAttentionModule(nn.Module):\n",
    "    def __init__(self,in_channels,reduction=16):\n",
    "        super(SEAttentionModule,self).__init__()\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = nn.Sequential(\n",
    "                  nn.Linear(in_channels,in_channels//reduction,bias=False),\n",
    "                  nn.ReLU(inplace=True),\n",
    "                  nn.Linear(in_channels//reduction,in_channels,bias=False))\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    def forward(self,x):\n",
    "        batch_size,channel,_ = x.view()\n",
    "        y = self.avgpool(x)\n",
    "        y = x.view(x.size(0),-1)\n",
    "        y = self.fc(x)\n",
    "        y = self.sigmoid(x)\n",
    "        y = y.view(batch_size,channel,1,1)\n",
    "        output = x * y\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SK attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SKConv(nn.Module):\n",
    "    def __init__(self, features, WH, M, G, r, stride=1 ,L=32):\n",
    "        \"\"\" Constructor\n",
    "        Args:\n",
    "            features: input channel dimensionality.\n",
    "            WH: input spatial dimensionality, used for GAP kernel size.\n",
    "            M: the number of branchs.\n",
    "            G: num of convolution groups.\n",
    "            r: the radio for compute d, the length of z.\n",
    "            stride: stride, default 1.\n",
    "            L: the minimum dim of the vector z in paper, default 32.\n",
    "        \"\"\"\n",
    "        super(SKConv, self).__init__()\n",
    "        d = max(int(features/r), L)\n",
    "        self.M = M\n",
    "        self.features = features\n",
    "        self.convs = nn.ModuleList([])\n",
    "        for i in range(M):\n",
    "            self.convs.append(nn.Sequential(\n",
    "                nn.Conv2d(features, features, kernel_size=3+i*2, stride=stride, padding=1+i, groups=G),\n",
    "                nn.BatchNorm2d(features),\n",
    "                nn.ReLU(inplace=False)\n",
    "            ))\n",
    "        # self.gap = nn.AvgPool2d(int(WH/stride))\n",
    "        self.fc = nn.Linear(features, d)\n",
    "        self.fcs = nn.ModuleList([])\n",
    "        for i in range(M):\n",
    "            self.fcs.append(\n",
    "                nn.Linear(d, features)\n",
    "            )\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        for i, conv in enumerate(self.convs):\n",
    "            fea = conv(x).unsqueeze_(dim=1)\n",
    "            if i == 0:\n",
    "                feas = fea\n",
    "            else:\n",
    "                feas = torch.cat([feas, fea], dim=1)\n",
    "        fea_U = torch.sum(feas, dim=1)\n",
    "        # fea_s = self.gap(fea_U).squeeze_()\n",
    "        fea_s = fea_U.mean(-1).mean(-1)\n",
    "        fea_z = self.fc(fea_s)\n",
    "        for i, fc in enumerate(self.fcs):\n",
    "            vector = fc(fea_z).unsqueeze_(dim=1)\n",
    "            if i == 0:\n",
    "                attention_vectors = vector\n",
    "            else:\n",
    "                attention_vectors = torch.cat([attention_vectors, vector], dim=1)\n",
    "        attention_vectors = self.softmax(attention_vectors)\n",
    "        attention_vectors = attention_vectors.unsqueeze(-1).unsqueeze(-1)\n",
    "        fea_v = (feas * attention_vectors).sum(dim=1)\n",
    "        return fea_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SKAttentionModule(nn.Module):\n",
    "    def __init__(self,in_channels,G,L=32):\n",
    "        super(SKAttentionModule,self).__init__()\n",
    "        d = max(int(in_channels/r),L)\n",
    "        \n",
    "        self.conv3x3 = nn.Sequential(\n",
    "             nn.Conv2d(in_channels, in_channels, kernel_size=3, padding=1, groups=G),\n",
    "             nn.BatchNorm2d(in_channels),\n",
    "             nn.ReLU(inplace=True)\n",
    "            )\n",
    "        self.conv5x5 = nn.Sequential(\n",
    "             nn.Conv2d(in_channels, in_channels, kernel_size=5, padding=2, groups=G),\n",
    "             nn.BatchNorm2d(in_channels),\n",
    "             nn.ReLU(inplace=True)\n",
    "            )\n",
    "        self.gp = nn.AvgPool2d(WH)\n",
    "        self.fc = nn.Linear(in_channels, d)\n",
    "        self.fcs_1 = nn.Linear(d,in_channels)\n",
    "        self.fcs_2 = nn.Linear(d,in_channels)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        branch1 = self.conv3x3(x)\n",
    "        branch2 = self.conv5x5(x)\n",
    "        branch_1_2 = torch.cat([branch1,branch2],dim=1)\n",
    "        \n",
    "        branch3 = branch1 + branch2\n",
    "        f_gp = self.gp(branch3)\n",
    "        f_fc = self.fc(f_gp)\n",
    "        f_fcs1 = self.fcs_1(f_fc)\n",
    "        f_fcs2 = self.fcs_2(f_fc)\n",
    "        attention_vectors = torch.cat([f_fcs1,f_fcs2],dim=1).softmax(dim=1)\n",
    "        attention_vectors = attention_vectors.view(attention_vectors.size(0),-1)\n",
    "        \n",
    "        output = attention_vectors * branch_1_2\n",
    "        \n",
    "        return output  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BAM Attention module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flatten(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return x.view(x.size(0), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChannelGate(nn.Module):\n",
    "    def __init__(self, gate_channel, reduction_ratio=16, num_layers=1):\n",
    "        super(ChannelGate, self).__init__()\n",
    "        self.gate_activation = gate_activation\n",
    "        self.gate_c = nn.Sequential()\n",
    "        self.gate_c.add_module( 'flatten', Flatten() )\n",
    "        gate_channels = [gate_channel]\n",
    "        gate_channels += [gate_channel // reduction_ratio] * num_layers\n",
    "        gate_channels += [gate_channel]\n",
    "        for i in range( len(gate_channels) - 2 ):\n",
    "            self.gate_c.add_module( 'gate_c_fc_%d'%i, nn.Linear(gate_channels[i], gate_channels[i+1]) )\n",
    "            self.gate_c.add_module( 'gate_c_bn_%d'%(i+1), nn.BatchNorm1d(gate_channels[i+1]) )\n",
    "            self.gate_c.add_module( 'gate_c_relu_%d'%(i+1), nn.ReLU() )\n",
    "        self.gate_c.add_module( 'gate_c_fc_final', nn.Linear(gate_channels[-2], gate_channels[-1]) )\n",
    "    def forward(self, in_tensor):\n",
    "        avg_pool = F.avg_pool2d( in_tensor, in_tensor.size(2), stride=in_tensor.size(2) )\n",
    "        return self.gate_c( avg_pool ).unsqueeze(2).unsqueeze(3).expand_as(in_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpatialGate(nn.Module):\n",
    "    def __init__(self, gate_channel, reduction_ratio=16, dilation_conv_num=2, dilation_val=4):\n",
    "        super(SpatialGate, self).__init__()\n",
    "        self.gate_s = nn.Sequential()\n",
    "        self.gate_s.add_module( 'gate_s_conv_reduce0', nn.Conv2d(gate_channel, gate_channel//reduction_ratio, kernel_size=1))\n",
    "        self.gate_s.add_module( 'gate_s_bn_reduce0',\tnn.BatchNorm2d(gate_channel//reduction_ratio) )\n",
    "        self.gate_s.add_module( 'gate_s_relu_reduce0',nn.ReLU() )\n",
    "        for i in range( dilation_conv_num ):\n",
    "            self.gate_s.add_module( 'gate_s_conv_di_%d'%i, \n",
    "                                   nn.Conv2d(gate_channel//reduction_ratio, gate_channel//reduction_ratio, \n",
    "                                             kernel_size=3, padding=dilation_val, dilation=dilation_val) )\n",
    "            self.gate_s.add_module( 'gate_s_bn_di_%d'%i, nn.BatchNorm2d(gate_channel//reduction_ratio) )\n",
    "            self.gate_s.add_module( 'gate_s_relu_di_%d'%i, nn.ReLU() )\n",
    "        self.gate_s.add_module( 'gate_s_conv_final', nn.Conv2d(gate_channel//reduction_ratio, 1, kernel_size=1) )\n",
    "    def forward(self, in_tensor):\n",
    "        return self.gate_s(in_tensor).expand_as(in_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BAM(nn.Module):\n",
    "    def __init__(self, gate_channel):\n",
    "        super(BAM, self).__init__()\n",
    "        self.channel_att = ChannelGate(gate_channel)\n",
    "        self.spatial_att = SpatialGate(gate_channel)\n",
    "    def forward(self,in_tensor):\n",
    "        att = 1 + F.sigmoid( self.channel_att(in_tensor) * self.spatial_att(in_tensor) )\n",
    "        return att * in_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChannelGate(nn.Module):\n",
    "    def __init__(in_channels,r):\n",
    "        super(ChannelGate,self).__init__()\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(in_channels,in_channels//r),\n",
    "            nn.BatchNorm2d(in_channels//r),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(in_channels//r,in_channels),\n",
    "            nn.BatchNorm2d(in_channels),\n",
    "            nn.ReLU(inplace=True))\n",
    "    def forward(self,x):\n",
    "        output = self.avgpool(output)\n",
    "        output = output.view(output.size(0),-1)\n",
    "        output = self.fc(output)\n",
    "        \n",
    "        return output.expand_as(x)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpatialGate(nn.Module):\n",
    "    def __init__(self,in_channels,ratio):\n",
    "        super(SpatialGate,self).__init__()\n",
    "        self.conv1x1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels,in_channels//ratio,kernel_size=1,padding=0),\n",
    "            nn.BatchNorm2d(in_channels//ratio),\n",
    "            nn.ReLU(inplace=True))\n",
    "        self.dilation_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels//ratio,in_channels//ratio,\n",
    "                      kernel_size=3,padding=4,dilation=4),#dilation conv\n",
    "            nn.BatchNorm2d(in_channels//ratio),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels//ratio,in_channels//ratio,\n",
    "                      kernel_size=3,padding=4,dilation=4),#dilation conv\n",
    "            nn.BatchNorm2d(in_channels//ratio),\n",
    "            nn.ReLU())\n",
    "        self.conv1x1_final = nn.Sequential(\n",
    "            nn.Conv2d(in_channels//ratio,1,kernel_size=1,padding=0))\n",
    "        def forward(self,x):\n",
    "            output = self.conv1x1(output)\n",
    "            output = self.dilation_conv(output)\n",
    "            output = conv1x1_final(output)\n",
    "            \n",
    "            return output.expand_as(output)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BAM(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super(BAM, self).__init__()\n",
    "        self.channel_attention = ChannelGate(in_channels)\n",
    "        self.spatial_attention = SpatialGate(in_channels)\n",
    "    def forward(self,x):\n",
    "        bam_attention = 1 + nn.Sigmoid(self.channel_attention(in_tensor) \n",
    "                                       * self.spatial_attention(in_tensor) )\n",
    "        return bam_attention * x"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
